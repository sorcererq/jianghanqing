
@Article{rs13224569,
AUTHOR = {Zhou, Liyang and Zhang, Zhuang and Jiang, Hanqing and Sun, Han and Bao, Hujun and Zhang, Guofeng},
TITLE = {DP-MVS: Detail Preserving Multi-View Surface Reconstruction of Large-Scale Scenes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4569},
URL = {https://www.mdpi.com/2072-4292/13/22/4569},
ISSN = {2072-4292},
ABSTRACT = {This paper presents an accurate and robust dense 3D reconstruction system for detail preserving surface modeling of large-scale scenes from multi-view images, which we named DP-MVS. Our system performs high-quality large-scale dense reconstruction, which preserves geometric details for thin structures, especially for linear objects. Our framework begins with a sparse reconstruction carried out by an incremental Structure-from-Motion. Based on the reconstructed sparse map, a novel detail preserving PatchMatch approach is applied for depth estimation of each image view. The estimated depth maps of multiple views are then fused to a dense point cloud in a memory-efficient way, followed by a detail-aware surface meshing method to extract the final surface mesh of the captured scene. Experiments on ETH3D benchmark show that the proposed method outperforms other state-of-the-art methods on F1-score, with the running time more than 4 times faster. More experiments on large-scale photo collections demonstrate the effectiveness of the proposed framework for large-scale scene reconstruction in terms of accuracy, completeness, memory saving, and time efficiency.},
DOI = {10.3390/rs13224569}
}



